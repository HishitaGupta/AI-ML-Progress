{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf558dc4",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ”¥ Top 20 REAL Data Scientist Interview Questions + Perfect Answers\n",
    "\n",
    "## 1. What is EDA and why is it important before modeling?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> EDA (Exploratory Data Analysis) is the process of understanding the structure, patterns, anomalies, and relationships in the data before building any model.\n",
    "> It helps me identify missing values, outliers, data leakage, incorrect assumptions and feature-target relationships.\n",
    "> In my projects, EDA has directly influenced my choice of model type and feature engineering strategy.\n",
    "\n",
    "**Importance:** â­â­â­â­â­ (Very high)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. How does skewed data affect model performance?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> Highly skewed data can bias the model because it gives more weight to extreme values and can violate assumptions of algorithms like linear regression.\n",
    "> In such cases, I apply transformations like log, square root, or Box-Cox transformations, or use robust models like tree-based algorithms.\n",
    "\n",
    "**Importance:** â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 3. When does the Central Limit Theorem NOT work?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> CLT may not hold well when the sample size is too small, data is heavily skewed, or has strong dependence between observations.\n",
    "> In real-world data, especially in time-series or highly skewed finance data, CLT can fail and lead to incorrect confidence intervals.\n",
    "\n",
    "**Importance:** â­â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Explain correlation vs causation with an example.\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> Correlation means two variables move together, but it doesnâ€™t imply one causes the other.\n",
    "> For example, ice cream sales and drowning cases increase together, but ice cream doesnâ€™t cause drowning. The hidden factor is summer.\n",
    "\n",
    "**Importance:** â­â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 5. How do you detect and handle outliers?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> I use boxplots, Z-score, and IQR methods to detect outliers.\n",
    "> Depending on the situation, I either remove them, cap them (winsorizing), or keep them if they represent genuine extreme events, such as fraud or rare conditions.\n",
    "\n",
    "**Importance:** â­â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 6. What is data leakage? How do you prevent it?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> Data leakage occurs when information from the future or test set leaks into the training process.\n",
    "> I prevent it by doing proper train-test split before preprocessing and using pipelines to ensure transformations are learned only from training data.\n",
    "\n",
    "**Very important for interviews** â­â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 7. What is multicollinearity and how do you solve it?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> Multicollinearity is when independent features are highly correlated with each other, which can make model coefficients unstable.\n",
    "> I detect it using correlation matrix and VIF and solve it by removing correlated variables or using PCA/regularization.\n",
    "\n",
    "**Importance** â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 8. If correlation is high but model accuracy is low, why?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> Because correlation captures only linear relationships. The real relationship might be non-linear, or other important features might be missing. It also could be overfitting or underfitting depending on model capacity.\n",
    "\n",
    "ðŸ”Ž Linear Relationship ->\n",
    "Definition: When two variables change at a constant rate with respect to each other. Graph: Straight line (positive slope, negative slope, or flat).\n",
    "Equation form: \n",
    "ð‘¦=ð‘Ž+ð‘ð‘¥\n",
    "Example:\n",
    "Hours studied vs. exam score â†’ more hours studied usually increases score in a fairly straight-line way.\n",
    "Distance = Speed Ã— Time â†’ perfectly linear.\n",
    "\n",
    "ðŸ”Ž Non-Linear Relationship ->\n",
    "Definition: When the rate of change between two variables is not constant. Graph: Curved line (could be exponential, quadratic, logarithmic, etc.). Equation form: \n",
    "ð‘¦=ð‘Ž+ð‘ð‘¥+ð‘ð‘¥2\n",
    "Example: Stress vs. performance â†’ initially stress improves performance (motivation), but too much stress reduces it (inverted U-shape). Population growth â†’ exponential curve, not a straight line.\n",
    "\n",
    "**Importance** â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 9. How do you choose which features to drop?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> I use a combination of:\n",
    "\n",
    "* Correlation analysis\n",
    "* Feature importance\n",
    "* Domain knowledge\n",
    "* VIF\n",
    "* Missing value percentage\n",
    "* Variance threshold\n",
    "\n",
    "Then I validate the decision by checking performance change after removal.\n",
    "\n",
    "**Importance** â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 10. How do you handle missing values?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> The strategy depends on the nature of the data.\n",
    "> For numeric features, I use mean/median/mode imputation or predictive models.\n",
    "> For categorical data, I use most frequent or create a new â€˜Unknownâ€™ category.\n",
    "\n",
    "**Importance** â­â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Describe a time where EDA changed your model selection.\n",
    "\n",
    "**Elite answer you can copy:**\n",
    "\n",
    "> During EDA, I noticed strong non-linear relationships and high skewness in features. That made me shift from Linear Regression to tree-based models like Random Forest and XGBoost, which improved performance significantly.\n",
    "\n",
    "**Importance** â­â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 12. What is the difference between supervised and unsupervised learning?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> Supervised learning uses labeled data for prediction while unsupervised learning finds patterns without labels, such as clustering and dimensionality reduction.\n",
    "\n",
    "**Importance** â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 13. What is the difference between sampling with and without replacement?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> With replacement: an element can be selected multiple times.\n",
    "> Without replacement: once selected, it cannot be chosen again, keeping probability dynamic.\n",
    "\n",
    "**Importance** â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 14. How do you check model bias?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> I check residual plots, fairness metrics, and performance across different subgroups to detect systemic bias.\n",
    "\n",
    "**Importance** â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 15. What is concept drift?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> Concept drift occurs when the statistical properties of the target variable change over time, reducing model accuracy.\n",
    "> To fix this, retraining and monitoring are essential.\n",
    "\n",
    "**Importance** â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 16. What metrics do you use for regression?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> RMSE, MAE, RÂ², and adjusted RÂ² depending on business requirements.\n",
    "\n",
    "**Importance** â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 17. What metrics do you use for classification?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> Precision, Recall, F1-Score, ROC-AUC, confusion matrix â€” accuracy alone is misleading for imbalanced datasets.\n",
    "\n",
    "**Importance** â­â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 18. When is accuracy misleading?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> In imbalanced datasets â€” e.g., 95% non-fraud data â€” a model can be 95% accurate but useless in detecting fraud.\n",
    "\n",
    "**Importance** â­â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 19. Difference between overfitting and underfitting?\n",
    "\n",
    "**Best answer:**\n",
    "\n",
    "> Overfitting: model memorizes training data, low bias, high variance.\n",
    "> Underfitting: model is too simple, high bias, low variance.\n",
    "\n",
    "**Importance** â­â­â­â­â­\n",
    "\n",
    "---\n",
    "\n",
    "## 20. Walk me through your Data Science project.\n",
    "\n",
    "**Perfect structure (USE THIS):**\n",
    "\n",
    "> 1. Problem statement\n",
    "> 2. Data collection\n",
    "> 3. EDA insights\n",
    "> 4. Feature engineering\n",
    "> 5. Model selection\n",
    "> 6. Evaluation metrics\n",
    "> 7. Business impact\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de84d26",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
