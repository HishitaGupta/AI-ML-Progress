{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f668fa7d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ SYSTEM DESIGN QUESTION 1 (DETAILED)\n",
    "\n",
    "## **Design a Resume Screening System using ML + GenAI**\n",
    "\n",
    "> Asked for: **AI Engineer / Applied Scientist / Data Scientist / GenAI Engineer**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ PROBLEM UNDERSTANDING (START LIKE THIS)\n",
    "\n",
    "**What you should say in interview:**\n",
    "\n",
    "> ‚ÄúThe goal is to automatically screen resumes against a job description, rank candidates, and optionally explain why a resume was shortlisted or rejected, while minimizing bias and false rejections.‚Äù\n",
    "\n",
    "This shows:\n",
    "\n",
    "* Business clarity\n",
    "* Ethical awareness\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ HIGH-LEVEL ARCHITECTURE (SAY THIS EARLY)\n",
    "\n",
    "```\n",
    "Resume ‚Üí Text Extraction ‚Üí Feature/Embedding Layer\n",
    "JD ‚Üí Embedding Layer\n",
    "Similarity / Ranking Model\n",
    "‚Üì\n",
    "Decision + Explanation (GenAI)\n",
    "‚Üì\n",
    "Dashboard / ATS Integration\n",
    "```\n",
    "\n",
    "Interviewers LOVE when you give a flow early.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ DATA LAYER (VERY IMPORTANT)\n",
    "\n",
    "### üì• Inputs\n",
    "\n",
    "* Resume files (PDF, DOCX)\n",
    "* Job Description (text)\n",
    "* Optional historical labels:\n",
    "\n",
    "  * shortlisted\n",
    "  * rejected\n",
    "  * hired\n",
    "\n",
    "### üß† Why this matters\n",
    "\n",
    "* Many real systems **don‚Äôt have labels**\n",
    "* So design must work **with and without supervision**\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ PREPROCESSING PIPELINE\n",
    "\n",
    "### Resume Processing\n",
    "\n",
    "* PDF/DOCX ‚Üí plain text\n",
    "* Remove noise (headers, footers)\n",
    "* Normalize text (lowercase, lemmatization)\n",
    "\n",
    "### NLP Enhancements\n",
    "\n",
    "* **Named Entity Recognition (NER)**\n",
    "  ‚Üí Skills, tools, degrees, experience\n",
    "* Date parsing\n",
    "  ‚Üí Years of experience\n",
    "\n",
    "üìå Interview tip:\n",
    "Say *‚Äúrule-based + ML hybrid extraction‚Äù* ‚Äî very realistic.\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ FEATURE ENGINEERING / EMBEDDINGS\n",
    "\n",
    "### üîπ Traditional ML option\n",
    "\n",
    "* TF-IDF vectors\n",
    "* Manually engineered features:\n",
    "\n",
    "  * years of experience\n",
    "  * skill match count\n",
    "\n",
    "### üîπ Modern (Preferred) Approach\n",
    "\n",
    "* **Sentence-BERT / OpenAI embeddings**\n",
    "* Convert:\n",
    "\n",
    "  * Resume ‚Üí vector\n",
    "  * JD ‚Üí vector\n",
    "\n",
    "### Similarity\n",
    "\n",
    "* Cosine similarity\n",
    "* Weighted scoring (skills > education)\n",
    "\n",
    "üìå Say this line:\n",
    "\n",
    "> ‚ÄúEmbeddings help capture semantic similarity beyond keyword matching.‚Äù\n",
    "\n",
    "This is a **golden sentence**.\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ MODEL LAYER (DECISION MAKING)\n",
    "\n",
    "### Option 1: Unsupervised (Most common)\n",
    "\n",
    "* Similarity score threshold\n",
    "* Rank resumes\n",
    "\n",
    "### Option 2: Supervised (If labels exist)\n",
    "\n",
    "* XGBoost / Logistic Regression\n",
    "* Input:\n",
    "\n",
    "  * similarity score\n",
    "  * experience\n",
    "  * skill overlap\n",
    "\n",
    "### Output\n",
    "\n",
    "* Shortlist probability\n",
    "* Rank order\n",
    "\n",
    "üìå Interviewers like when you say:\n",
    "\n",
    "> ‚ÄúWe start simple and move to supervised once labels mature.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ GENAI LAYER (THIS MAKES YOU STAND OUT üî•)\n",
    "\n",
    "### Why GenAI?\n",
    "\n",
    "* HR wants **explanations**, not just scores\n",
    "\n",
    "### Use LLM to:\n",
    "\n",
    "* Summarize resume in 3 bullets\n",
    "* Explain:\n",
    "\n",
    "  * ‚ÄúWhy shortlisted‚Äù\n",
    "  * ‚ÄúWhat skills are missing‚Äù\n",
    "* Normalize resume formats\n",
    "\n",
    "### Prompt example (mention conceptually):\n",
    "\n",
    "> ‚ÄúGiven JD and resume summary, explain match in neutral tone.‚Äù\n",
    "\n",
    "üìå This shows **applied GenAI**, not hype.\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ INFERENCE FLOW (CLEAR STEP-BY-STEP)\n",
    "\n",
    "```\n",
    "1. Upload resume\n",
    "2. Extract text\n",
    "3. Generate embeddings\n",
    "4. Compare with JD embeddings\n",
    "5. Rank candidates\n",
    "6. LLM generates explanation\n",
    "7. Send to recruiter dashboard\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ SCALABILITY & PERFORMANCE\n",
    "\n",
    "### Scaling Techniques\n",
    "\n",
    "* Precompute resume embeddings\n",
    "* Vector DB (FAISS / Pinecone)\n",
    "* Async batch processing\n",
    "\n",
    "### Latency\n",
    "\n",
    "* Screening: batch mode\n",
    "* Explanation: on-demand\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúWe decouple ranking and explanation to save cost.‚Äù\n",
    "\n",
    "Very strong signal.\n",
    "\n",
    "---\n",
    "\n",
    "## üîü EVALUATION METRICS\n",
    "\n",
    "### ML Metrics\n",
    "\n",
    "* Precision@K\n",
    "* Recall@K (important!)\n",
    "* False rejection rate\n",
    "\n",
    "### Human Metrics\n",
    "\n",
    "* Recruiter satisfaction\n",
    "* Interview-to-hire ratio\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúRecall is more important because missing good candidates is costly.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ BIAS & ETHICS (DO NOT SKIP)\n",
    "\n",
    "### Bias Risks\n",
    "\n",
    "* Gender\n",
    "* College\n",
    "* Resume format bias\n",
    "\n",
    "### Mitigation\n",
    "\n",
    "* Remove names & colleges\n",
    "* Regular bias audits\n",
    "* Human-in-the-loop\n",
    "\n",
    "Interviewers **will judge maturity here**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£ FAILURE CASES & IMPROVEMENTS\n",
    "\n",
    "* New job roles ‚Üí poor embeddings\n",
    "* Creative resumes ‚Üí parsing errors\n",
    "\n",
    "### Improvements\n",
    "\n",
    "* Feedback loop\n",
    "* Periodic fine-tuning\n",
    "* Domain-specific embeddings\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabce287",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ PROBLEM STATEMENT (START STRONG)\n",
    "\n",
    "**What you should say first:**\n",
    "\n",
    "> ‚ÄúWe want to design a conversational AI system that can understand user queries, generate coherent and safe responses in real time, scale to millions of users, and continuously improve using feedback.‚Äù\n",
    "\n",
    "This signals:\n",
    "\n",
    "* Product thinking\n",
    "* Scale awareness\n",
    "* Safety awareness\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ HIGH-LEVEL ARCHITECTURE (ALWAYS DO THIS)\n",
    "\n",
    "```\n",
    "User Query\n",
    "   ‚Üì\n",
    "Safety & Moderation\n",
    "   ‚Üì\n",
    "Prompt Construction\n",
    "   ‚Üì\n",
    "LLM Inference Engine\n",
    "   ‚Üì\n",
    "Post-processing & Safety\n",
    "   ‚Üì\n",
    "Response to User\n",
    "```\n",
    "\n",
    "Interviewers **expect a flow diagram in words**.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ INPUT & PREPROCESSING LAYER\n",
    "\n",
    "### Input\n",
    "\n",
    "* User text\n",
    "* Conversation history\n",
    "* Optional metadata (language, region)\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "* Profanity / policy filtering\n",
    "* Tokenization\n",
    "* Context window management\n",
    "\n",
    "üìå **Important line to say:**\n",
    "\n",
    "> ‚ÄúWe carefully select how much chat history to include to stay within the context window.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ PROMPT ENGINEERING LAYER (VERY IMPORTANT)\n",
    "\n",
    "### Why?\n",
    "\n",
    "LLMs behave based on prompts.\n",
    "\n",
    "### Prompt Components\n",
    "\n",
    "* System prompt (role & behavior)\n",
    "* Conversation history\n",
    "* User query\n",
    "* Safety instructions\n",
    "\n",
    "Example (conceptually):\n",
    "\n",
    "```\n",
    "You are a helpful assistant.\n",
    "Follow safety rules.\n",
    "Conversation history: ...\n",
    "User question: ...\n",
    "```\n",
    "\n",
    "üìå Interviewer signal:\n",
    "\n",
    "> You understand LLMs are **not magic**, they‚Äôre prompt-driven.\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ CORE MODEL LAYER (LLM)\n",
    "\n",
    "### Model Options\n",
    "\n",
    "* GPT-like (decoder-only transformer)\n",
    "* LLaMA / Mistral (self-hosted)\n",
    "* Fine-tuned domain model\n",
    "\n",
    "### Training Stages (MENTION THIS)\n",
    "\n",
    "1. Pre-training (internet scale data)\n",
    "2. Supervised fine-tuning (SFT)\n",
    "3. RLHF (human feedback)\n",
    "\n",
    "üìå **Golden sentence:**\n",
    "\n",
    "> ‚ÄúRLHF aligns model outputs with human expectations.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ INFERENCE & GENERATION\n",
    "\n",
    "### Decoding Strategies\n",
    "\n",
    "* Temperature (creativity)\n",
    "* Top-p (nucleus sampling)\n",
    "* Max tokens\n",
    "\n",
    "### Streaming\n",
    "\n",
    "* Token-by-token response\n",
    "* Improves UX\n",
    "\n",
    "üìå Interviewers like:\n",
    "\n",
    "> ‚ÄúStreaming reduces perceived latency.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ SAFETY & POST-PROCESSING (DO NOT SKIP)\n",
    "\n",
    "### Post-Generation Checks\n",
    "\n",
    "* Toxicity filter\n",
    "* Hallucination checks\n",
    "* PII removal\n",
    "\n",
    "### Why?\n",
    "\n",
    "LLMs can generate:\n",
    "\n",
    "* Confidently wrong answers\n",
    "* Unsafe content\n",
    "\n",
    "üìå Say this clearly:\n",
    "\n",
    "> ‚ÄúSafety checks happen both before and after generation.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ SCALABILITY & PERFORMANCE\n",
    "\n",
    "### Challenges\n",
    "\n",
    "* High compute cost\n",
    "* Low latency requirement\n",
    "\n",
    "### Solutions\n",
    "\n",
    "* Load balancing\n",
    "* KV caching\n",
    "* Quantization (INT8 / INT4)\n",
    "* Model sharding\n",
    "\n",
    "üìå Strong line:\n",
    "\n",
    "> ‚ÄúCaching repeated queries dramatically reduces inference cost.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ COST OPTIMIZATION (VERY HOT QUESTION)\n",
    "\n",
    "Ways to reduce cost:\n",
    "\n",
    "* Smaller distilled models\n",
    "* Prompt compression\n",
    "* RAG instead of fine-tuning\n",
    "* Response caching\n",
    "\n",
    "Interviewers **love cost awareness**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîü MONITORING & EVALUATION\n",
    "\n",
    "### Metrics\n",
    "\n",
    "* Latency\n",
    "* User satisfaction\n",
    "* Hallucination rate\n",
    "* Safety violation rate\n",
    "\n",
    "### Feedback Loop\n",
    "\n",
    "* Thumbs up/down\n",
    "* Human review\n",
    "* Retraining data\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúUser feedback is critical for continuous improvement.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ FAILURE CASES\n",
    "\n",
    "* Hallucinations\n",
    "* Context forgetting\n",
    "* Prompt injection attacks\n",
    "\n",
    "### Mitigation\n",
    "\n",
    "* RAG grounding\n",
    "* Strict prompt templates\n",
    "* Input sanitization\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£ EXTENSIONS (OPTIONAL BUT IMPRESSIVE)\n",
    "\n",
    "* Multi-modal (text + image)\n",
    "* Tool calling (calculator, search)\n",
    "* Memory per user\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ HOW INTERVIEWERS EVALUATE THIS\n",
    "\n",
    "| Area                 | Signal |\n",
    "| -------------------- | ------ |\n",
    "| LLM understanding    | ‚úÖ      |\n",
    "| Practical deployment | ‚úÖ      |\n",
    "| Safety awareness     | ‚úÖ      |\n",
    "| Cost & scale         | ‚úÖ      |\n",
    "| Product thinking     | ‚úÖ      |\n",
    "\n",
    "This answer = **strong GenAI engineer signal**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d1fb32",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ SYSTEM DESIGN QUESTION 3 (DETAILED)\n",
    "\n",
    "## **Design a Recommendation System (Netflix / YouTube / Amazon)**\n",
    "\n",
    "> Asked in: **Google, Amazon, Netflix, Meta, Flipkart, Walmart**\n",
    "> Roles: **Data Scientist, ML Engineer, Applied Scientist**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ PROBLEM STATEMENT (HOW TO START)\n",
    "\n",
    "**Say this first:**\n",
    "\n",
    "> ‚ÄúThe goal is to recommend relevant items to users to maximize engagement such as watch time, clicks, or purchases, while handling scale, cold start, and personalization.‚Äù\n",
    "\n",
    "This shows:\n",
    "\n",
    "* Business understanding\n",
    "* ML maturity\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ HIGH-LEVEL ARCHITECTURE (ALWAYS)\n",
    "\n",
    "```\n",
    "User Interaction Data\n",
    "Item Metadata\n",
    "‚Üì\n",
    "Feature / Embedding Generation\n",
    "‚Üì\n",
    "Candidate Generation\n",
    "‚Üì\n",
    "Ranking Model\n",
    "‚Üì\n",
    "Recommendation Output\n",
    "```\n",
    "\n",
    "Interviewers expect **multi-stage design**, not ‚Äújust KNN‚Äù.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ DATA LAYER (VERY IMPORTANT)\n",
    "\n",
    "### User Data\n",
    "\n",
    "* Clicks\n",
    "* Watch history\n",
    "* Likes\n",
    "* Time spent\n",
    "* Search queries\n",
    "\n",
    "### Item Data\n",
    "\n",
    "* Category\n",
    "* Tags\n",
    "* Text description\n",
    "* Images\n",
    "* Creator metadata\n",
    "\n",
    "üìå Say this:\n",
    "\n",
    "> ‚ÄúWe combine implicit and explicit feedback.‚Äù\n",
    "\n",
    "Implicit feedback = very important.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ COLD START PROBLEM (INTERVIEW FAVORITE)\n",
    "\n",
    "### New User\n",
    "\n",
    "* Use popular/trending items\n",
    "* Ask onboarding questions\n",
    "* Demographic-based recommendations\n",
    "\n",
    "### New Item\n",
    "\n",
    "* Content-based features\n",
    "* Metadata embeddings\n",
    "* Explore via limited exposure\n",
    "\n",
    "üìå Golden line:\n",
    "\n",
    "> ‚ÄúCold start is solved primarily using content-based approaches.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ FEATURE ENGINEERING / EMBEDDINGS\n",
    "\n",
    "### Traditional Features\n",
    "\n",
    "* User-item interaction counts\n",
    "* Time decay features\n",
    "* Category affinity\n",
    "\n",
    "### Modern Approach (PREFERRED)\n",
    "\n",
    "* User embeddings\n",
    "* Item embeddings\n",
    "\n",
    "Generated using:\n",
    "\n",
    "* Matrix factorization\n",
    "* Neural networks\n",
    "* Transformer-based models\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúEmbeddings allow us to represent users and items in the same vector space.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ CANDIDATE GENERATION (FIRST STAGE)\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Reduce millions of items ‚Üí few thousand candidates\n",
    "\n",
    "### Methods\n",
    "\n",
    "* Collaborative filtering\n",
    "* Approximate nearest neighbors\n",
    "* Content similarity\n",
    "\n",
    "### Tools\n",
    "\n",
    "* FAISS\n",
    "* ScaNN\n",
    "* ANN libraries\n",
    "\n",
    "üìå Interviewer signal:\n",
    "\n",
    "> You understand **retrieval vs ranking separation**.\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ RANKING MODEL (MOST IMPORTANT)\n",
    "\n",
    "### Input\n",
    "\n",
    "* User embedding\n",
    "* Item embedding\n",
    "* Context (time, device)\n",
    "\n",
    "### Models\n",
    "\n",
    "* XGBoost\n",
    "* DNN\n",
    "* Wide & Deep\n",
    "* Transformer-based ranking\n",
    "\n",
    "### Output\n",
    "\n",
    "* Ranked list of items\n",
    "\n",
    "üìå Say this:\n",
    "\n",
    "> ‚ÄúRanking models optimize business objectives, not just relevance.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ TRAINING PIPELINE\n",
    "\n",
    "### Offline Training\n",
    "\n",
    "* Historical data\n",
    "* Negative sampling\n",
    "* Time-based splits\n",
    "\n",
    "### Online Learning (Optional)\n",
    "\n",
    "* Real-time feedback\n",
    "* Reinforcement learning\n",
    "\n",
    "üìå Strong signal:\n",
    "\n",
    "> ‚ÄúWe avoid data leakage using time-aware splits.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ EVALUATION METRICS (VERY IMPORTANT)\n",
    "\n",
    "### Offline\n",
    "\n",
    "* Precision@K\n",
    "* Recall@K\n",
    "* NDCG\n",
    "\n",
    "### Online\n",
    "\n",
    "* CTR\n",
    "* Watch time\n",
    "* Conversion rate\n",
    "\n",
    "üìå Say clearly:\n",
    "\n",
    "> ‚ÄúOnline A/B testing is the final authority.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## üîü SCALABILITY & LATENCY\n",
    "\n",
    "### Challenges\n",
    "\n",
    "* Millions of users\n",
    "* Real-time inference\n",
    "\n",
    "### Solutions\n",
    "\n",
    "* Precomputed embeddings\n",
    "* Caching\n",
    "* Distributed inference\n",
    "* Async pipelines\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ FEEDBACK LOOP\n",
    "\n",
    "* User actions ‚Üí training data\n",
    "* Bias towards popular items ‚Üí mitigate using exploration\n",
    "\n",
    "üìå Mention:\n",
    "\n",
    "> ‚ÄúWe balance exploitation and exploration.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£ FAILURE CASES\n",
    "\n",
    "* Filter bubbles\n",
    "* Over-personalization\n",
    "* Popularity bias\n",
    "\n",
    "### Mitigation\n",
    "\n",
    "* Diversity constraints\n",
    "* Re-ranking\n",
    "* Random exploration\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£3Ô∏è‚É£ GENAI EXTENSION (BONUS üî•)\n",
    "\n",
    "### Use GenAI to:\n",
    "\n",
    "* Explain recommendations\n",
    "* Generate item descriptions\n",
    "* Personalize UI text\n",
    "\n",
    "üìå This line impresses:\n",
    "\n",
    "> ‚ÄúGenAI enhances explainability, not core ranking.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ HOW INTERVIEWERS SCORE THIS\n",
    "\n",
    "| Area              | Signal |\n",
    "| ----------------- | ------ |\n",
    "| ML depth          | ‚úÖ      |\n",
    "| Real-world scale  | ‚úÖ      |\n",
    "| Metrics           | ‚úÖ      |\n",
    "| Business thinking | ‚úÖ      |\n",
    "| Modern approach   | ‚úÖ      |\n",
    "\n",
    "This answer = **top-tier ML candidate**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82917d5",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ SYSTEM DESIGN QUESTION 4 (DETAILED)\n",
    "\n",
    "## **Design a RAG (Retrieval-Augmented Generation) System**\n",
    "\n",
    "> Asked in: **GenAI Engineer, Applied Scientist, AI Platform roles**\n",
    "> Companies: **Google, Microsoft, Amazon, startups**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ PROBLEM STATEMENT (START LIKE THIS)\n",
    "\n",
    "**Say this clearly:**\n",
    "\n",
    "> ‚ÄúThe goal of a RAG system is to generate accurate, up-to-date, and domain-specific answers by grounding an LLM on external knowledge sources, thereby reducing hallucinations.‚Äù\n",
    "\n",
    "This immediately signals:\n",
    "\n",
    "* You understand *why* RAG exists\n",
    "* You‚Äôre not blindly using LLMs\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ WHY RAG IS NEEDED (INTERVIEW FAVORITE)\n",
    "\n",
    "### Problems with plain LLMs\n",
    "\n",
    "* Hallucinations\n",
    "* No access to private data\n",
    "* Knowledge cutoff\n",
    "* Expensive fine-tuning\n",
    "\n",
    "### RAG solves this by:\n",
    "\n",
    "* Retrieving relevant context\n",
    "* Injecting it into the prompt\n",
    "* Letting LLM answer **based on evidence**\n",
    "\n",
    "üìå **Golden line**:\n",
    "\n",
    "> ‚ÄúRAG separates knowledge from reasoning.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ HIGH-LEVEL ARCHITECTURE\n",
    "\n",
    "```\n",
    "Documents\n",
    "  ‚Üì\n",
    "Chunking + Cleaning\n",
    "  ‚Üì\n",
    "Embeddings\n",
    "  ‚Üì\n",
    "Vector Database\n",
    "  ‚Üì\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "User Query\n",
    "  ‚Üì\n",
    "Query Embedding\n",
    "  ‚Üì\n",
    "Top-K Retrieval\n",
    "  ‚Üì\n",
    "Context + Query\n",
    "  ‚Üì\n",
    "LLM\n",
    "  ‚Üì\n",
    "Final Answer\n",
    "```\n",
    "\n",
    "Interviewers expect **this flow**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ DOCUMENT INGESTION PIPELINE\n",
    "\n",
    "### Supported Sources\n",
    "\n",
    "* PDFs\n",
    "* Docs\n",
    "* Web pages\n",
    "* Databases\n",
    "* Internal wikis\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "* Remove boilerplate\n",
    "* Normalize text\n",
    "* Handle tables/code separately\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúClean ingestion is critical; garbage in leads to hallucinated answers.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ CHUNKING STRATEGY (VERY IMPORTANT üî•)\n",
    "\n",
    "### Why chunking?\n",
    "\n",
    "* LLM context window is limited\n",
    "* Long documents dilute relevance\n",
    "\n",
    "### Chunking Methods\n",
    "\n",
    "* Fixed-size (e.g. 500 tokens)\n",
    "* Sliding window\n",
    "* Semantic chunking (preferred)\n",
    "\n",
    "### Best Practice\n",
    "\n",
    "* 300‚Äì800 tokens\n",
    "* Overlap of 50‚Äì100 tokens\n",
    "\n",
    "üìå Interviewer signal:\n",
    "\n",
    "> You‚Äôve built RAG systems before.\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ EMBEDDING GENERATION\n",
    "\n",
    "### Models\n",
    "\n",
    "* OpenAI embeddings\n",
    "* Sentence-BERT\n",
    "* Domain-specific embeddings\n",
    "\n",
    "### What gets embedded?\n",
    "\n",
    "* Each chunk\n",
    "* Metadata (title, section)\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúWe embed chunks, not full documents.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ VECTOR DATABASE\n",
    "\n",
    "### Purpose\n",
    "\n",
    "* Fast similarity search\n",
    "\n",
    "### Popular Options\n",
    "\n",
    "* FAISS (open-source)\n",
    "* Pinecone\n",
    "* Weaviate\n",
    "* Milvus\n",
    "\n",
    "### Stored Data\n",
    "\n",
    "* Embedding vector\n",
    "* Chunk text\n",
    "* Metadata\n",
    "\n",
    "üìå Strong line:\n",
    "\n",
    "> ‚ÄúVector DB enables millisecond-level semantic retrieval.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ QUERY PROCESSING (INFERENCE PATH)\n",
    "\n",
    "### Step-by-step\n",
    "\n",
    "1. User query\n",
    "2. Generate query embedding\n",
    "3. Retrieve top-K relevant chunks\n",
    "4. Rerank (optional)\n",
    "5. Build prompt\n",
    "6. Call LLM\n",
    "\n",
    "üìå Mention reranking:\n",
    "\n",
    "> ‚ÄúA cross-encoder reranker improves relevance.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ PROMPT CONSTRUCTION (CRITICAL)\n",
    "\n",
    "### Prompt Template\n",
    "\n",
    "* System instruction\n",
    "* Retrieved context\n",
    "* User query\n",
    "* Strict grounding instruction\n",
    "\n",
    "Example (conceptual):\n",
    "\n",
    "> ‚ÄúAnswer only using the context below. If not found, say you don‚Äôt know.‚Äù\n",
    "\n",
    "üìå This shows hallucination control.\n",
    "\n",
    "---\n",
    "\n",
    "## üîü LLM GENERATION\n",
    "\n",
    "### Model\n",
    "\n",
    "* GPT / Claude / LLaMA\n",
    "* Smaller models often sufficient due to grounding\n",
    "\n",
    "### Decoding\n",
    "\n",
    "* Low temperature\n",
    "* Deterministic output\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúRAG allows us to use smaller, cheaper models.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ EVALUATION METRICS (INTERVIEWERS LOVE THIS)\n",
    "\n",
    "### Retrieval Metrics\n",
    "\n",
    "* Recall@K\n",
    "* Context relevance\n",
    "\n",
    "### Generation Metrics\n",
    "\n",
    "* Faithfulness\n",
    "* Answer correctness\n",
    "* Hallucination rate\n",
    "\n",
    "### Human Evaluation\n",
    "\n",
    "* Trust score\n",
    "* Answer usefulness\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£ SCALABILITY & COST\n",
    "\n",
    "### Challenges\n",
    "\n",
    "* Large document corpus\n",
    "* Frequent updates\n",
    "\n",
    "### Solutions\n",
    "\n",
    "* Incremental indexing\n",
    "* Caching embeddings\n",
    "* Async ingestion\n",
    "* Batch retrieval\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúWe avoid re-embedding unchanged documents.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£3Ô∏è‚É£ FAILURE CASES & MITIGATION\n",
    "\n",
    "### Failure Modes\n",
    "\n",
    "* Wrong chunk retrieved\n",
    "* Missing information\n",
    "* Conflicting documents\n",
    "\n",
    "### Fixes\n",
    "\n",
    "* Better chunking\n",
    "* Metadata filtering\n",
    "* Hybrid search (BM25 + embeddings)\n",
    "\n",
    "üìå Hybrid search mention = strong signal.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£4Ô∏è‚É£ WHEN NOT TO USE RAG (ADVANCED)\n",
    "\n",
    "Say this if asked:\n",
    "\n",
    "* Very small datasets\n",
    "* Tasks needing creativity\n",
    "* Heavy reasoning without facts\n",
    "\n",
    "üìå Shows balanced thinking.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£5Ô∏è‚É£ REAL-WORLD USE CASES\n",
    "\n",
    "* Enterprise Q&A\n",
    "* Customer support bots\n",
    "* Legal document search\n",
    "* Internal knowledge assistants\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ HOW INTERVIEWERS SCORE THIS\n",
    "\n",
    "| Area                 | Signal |\n",
    "| -------------------- | ------ |\n",
    "| GenAI depth          | ‚úÖ      |\n",
    "| Practical knowledge  | ‚úÖ      |\n",
    "| Anti-hallucination   | ‚úÖ      |\n",
    "| Cost awareness       | ‚úÖ      |\n",
    "| Production readiness | ‚úÖ      |\n",
    "\n",
    "This answer = **GenAI interview gold standard**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d795d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ SYSTEM DESIGN QUESTION 5 (DETAILED)\n",
    "\n",
    "## **Design a Fraud Detection System**\n",
    "\n",
    "> Asked in: **Data Scientist, ML Engineer, Applied Scientist**\n",
    "> Companies: **Amazon, PayPal, Stripe, Flipkart, PhonePe, Google**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ PROBLEM STATEMENT (HOW TO START)\n",
    "\n",
    "Say this:\n",
    "\n",
    "> ‚ÄúThe goal is to detect fraudulent transactions in real time while minimizing false positives, since incorrectly blocking genuine users impacts business.‚Äù\n",
    "\n",
    "üî• This shows **business + ML thinking**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ KEY CHALLENGES (INTERVIEW FAVORITE)\n",
    "\n",
    "Mention **all three**:\n",
    "\n",
    "1. **Extreme class imbalance** (fraud < 1%)\n",
    "2. **Real-time latency constraints**\n",
    "3. **Concept drift** (fraud patterns change)\n",
    "\n",
    "üìå Strong line:\n",
    "\n",
    "> ‚ÄúFraud detection is not a pure accuracy problem; it‚Äôs a cost-sensitive classification problem.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ HIGH-LEVEL ARCHITECTURE\n",
    "\n",
    "```\n",
    "Transaction Event\n",
    "   ‚Üì\n",
    "Feature Engineering\n",
    "   ‚Üì\n",
    "Fraud Model\n",
    "   ‚Üì\n",
    "Risk Score\n",
    "   ‚Üì\n",
    "Decision Engine\n",
    "   ‚Üì\n",
    "Approve / Block / Manual Review\n",
    "```\n",
    "\n",
    "Simple, clean, interview-ready.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ DATA SOURCES\n",
    "\n",
    "### Transaction Data\n",
    "\n",
    "* Amount\n",
    "* Timestamp\n",
    "* Merchant\n",
    "* Payment method\n",
    "\n",
    "### User Behavior\n",
    "\n",
    "* Transaction frequency\n",
    "* Location changes\n",
    "* Device fingerprint\n",
    "\n",
    "### Historical Labels\n",
    "\n",
    "* Chargebacks\n",
    "* User complaints\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúLabels are delayed and noisy in fraud systems.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ FEATURE ENGINEERING (VERY IMPORTANT üî•)\n",
    "\n",
    "### Transaction-level Features\n",
    "\n",
    "* Amount vs user‚Äôs average\n",
    "* Time since last transaction\n",
    "\n",
    "### Aggregation Features\n",
    "\n",
    "* Transactions in last 1h / 24h / 7d\n",
    "* Velocity features\n",
    "\n",
    "### Behavioral Features\n",
    "\n",
    "* IP mismatch\n",
    "* Country change\n",
    "* New device\n",
    "\n",
    "üìå Golden line:\n",
    "\n",
    "> ‚ÄúVelocity-based features are the backbone of fraud detection.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ MODELING APPROACH\n",
    "\n",
    "### Baseline Models\n",
    "\n",
    "* Logistic Regression (interpretable)\n",
    "* Decision Trees\n",
    "\n",
    "### Advanced Models\n",
    "\n",
    "* XGBoost / LightGBM (industry standard)\n",
    "* Random Forest\n",
    "\n",
    "### Deep Learning (optional)\n",
    "\n",
    "* LSTM for sequences\n",
    "* Graph-based models for fraud rings\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúTree-based models dominate fraud detection due to tabular data.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ HANDLING CLASS IMBALANCE (CRITICAL)\n",
    "\n",
    "### Techniques\n",
    "\n",
    "* Class-weighted loss\n",
    "* SMOTE (offline only)\n",
    "* Undersampling majority class\n",
    "\n",
    "üìå IMPORTANT:\n",
    "\n",
    "> ‚ÄúI avoid accuracy and focus on recall for fraud.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ EVALUATION METRICS (VERY IMPORTANT üî•)\n",
    "\n",
    "### Primary Metrics\n",
    "\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score\n",
    "* ROC-AUC\n",
    "* PR-AUC (preferred)\n",
    "\n",
    "### Business Metric\n",
    "\n",
    "* Fraud dollars saved\n",
    "* False positive rate\n",
    "\n",
    "üìå Strong line:\n",
    "\n",
    "> ‚ÄúPR-AUC is more informative than ROC-AUC for imbalanced data.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ THRESHOLDING & DECISION LOGIC\n",
    "\n",
    "Risk score ‚Üí decision:\n",
    "\n",
    "| Score  | Action        |\n",
    "| ------ | ------------- |\n",
    "| Low    | Auto-approve  |\n",
    "| Medium | Manual review |\n",
    "| High   | Block         |\n",
    "\n",
    "üìå Interviewer signal:\n",
    "\n",
    "> You understand real systems.\n",
    "\n",
    "---\n",
    "\n",
    "## üîü REAL-TIME VS BATCH\n",
    "\n",
    "### Real-Time\n",
    "\n",
    "* Lightweight features\n",
    "* Low-latency models\n",
    "* Kafka / streaming\n",
    "\n",
    "### Batch\n",
    "\n",
    "* Heavy aggregations\n",
    "* Model retraining\n",
    "* Feature recomputation\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúTraining is batch, inference is real-time.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ CONCEPT DRIFT HANDLING\n",
    "\n",
    "### Detection\n",
    "\n",
    "* PSI (Population Stability Index)\n",
    "* Feature distribution shift\n",
    "\n",
    "### Mitigation\n",
    "\n",
    "* Frequent retraining\n",
    "* Champion‚Äìchallenger models\n",
    "\n",
    "üìå Very strong signal.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£ EXPLAINABILITY (IMPORTANT)\n",
    "\n",
    "### Why?\n",
    "\n",
    "* Compliance\n",
    "* Trust\n",
    "\n",
    "### Tools\n",
    "\n",
    "* SHAP\n",
    "* Feature importance\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúEvery fraud decision must be explainable.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£3Ô∏è‚É£ FAILURE CASES\n",
    "\n",
    "* New fraud patterns\n",
    "* Adversarial attacks\n",
    "* Delayed labels\n",
    "\n",
    "### Fix\n",
    "\n",
    "* Semi-supervised learning\n",
    "* Rule-based fallback\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£4Ô∏è‚É£ REAL-WORLD USE CASES\n",
    "\n",
    "* Credit card fraud\n",
    "* Insurance fraud\n",
    "* E-commerce refunds\n",
    "* Account takeover\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£5Ô∏è‚É£ INTERVIEWER SCORING\n",
    "\n",
    "| Area                   | Signal |\n",
    "| ---------------------- | ------ |\n",
    "| Business understanding | ‚úÖ      |\n",
    "| Feature engineering    | ‚úÖ      |\n",
    "| Metrics                | ‚úÖ      |\n",
    "| Production awareness   | ‚úÖ      |\n",
    "| ML depth               | ‚úÖ      |\n",
    "\n",
    "This answer is **exactly what Amazon / Stripe expect**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf2798",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ SYSTEM DESIGN QUESTION 6 (DETAILED)\n",
    "\n",
    "## **Design a Recommendation System (ML + GenAI perspective)**\n",
    "\n",
    "> Asked in: **Amazon, Netflix, Google, Meta, Spotify, Flipkart, Microsoft**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ PROBLEM STATEMENT (HOW TO START)\n",
    "\n",
    "Say this:\n",
    "\n",
    "> ‚ÄúThe goal of a recommendation system is to surface the most relevant items to users in order to maximize engagement, retention, or revenue.‚Äù\n",
    "\n",
    "üéØ Interviewers want **business alignment first**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ TYPES OF RECOMMENDATION SYSTEMS\n",
    "\n",
    "### 1. Content-Based Filtering\n",
    "\n",
    "* Uses item features\n",
    "* Personalized per user\n",
    "* Cold-start friendly (for users)\n",
    "\n",
    "### 2. Collaborative Filtering\n",
    "\n",
    "* User‚Äìuser or item‚Äìitem similarity\n",
    "* Learns from behavior\n",
    "* Suffers from cold-start\n",
    "\n",
    "### 3. Hybrid Systems (Industry Standard)\n",
    "\n",
    "* Combines both\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúAll production systems are hybrid.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ HIGH-LEVEL ARCHITECTURE\n",
    "\n",
    "```\n",
    "User Interaction Data\n",
    "        ‚Üì\n",
    "Feature Store\n",
    "        ‚Üì\n",
    "Candidate Generation\n",
    "        ‚Üì\n",
    "Ranking Model\n",
    "        ‚Üì\n",
    "Post-processing\n",
    "        ‚Üì\n",
    "Final Recommendations\n",
    "```\n",
    "\n",
    "üî• This pipeline structure is **mandatory knowledge**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ DATA SOURCES\n",
    "\n",
    "### User Data\n",
    "\n",
    "* Clicks\n",
    "* Likes\n",
    "* Watch time\n",
    "* Search history\n",
    "\n",
    "### Item Data\n",
    "\n",
    "* Metadata\n",
    "* Text description\n",
    "* Tags\n",
    "* Images\n",
    "\n",
    "### Context Data\n",
    "\n",
    "* Time\n",
    "* Device\n",
    "* Location\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ FEATURE ENGINEERING (CRITICAL)\n",
    "\n",
    "### User Features\n",
    "\n",
    "* Embeddings\n",
    "* Recent behavior\n",
    "* Long-term interests\n",
    "\n",
    "### Item Features\n",
    "\n",
    "* Category\n",
    "* Text embeddings\n",
    "* Popularity\n",
    "\n",
    "### Interaction Features\n",
    "\n",
    "* Click-through rate\n",
    "* Dwell time\n",
    "\n",
    "üìå Strong line:\n",
    "\n",
    "> ‚ÄúRecency-weighted features outperform static ones.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ TWO-STAGE MODELING (VERY IMPORTANT üî•)\n",
    "\n",
    "### Stage 1: Candidate Generation\n",
    "\n",
    "* Fast & scalable\n",
    "* Retrieves ~1000 items\n",
    "\n",
    "Models:\n",
    "\n",
    "* Matrix Factorization\n",
    "* ANN (FAISS)\n",
    "* Two-tower models\n",
    "\n",
    "### Stage 2: Ranking\n",
    "\n",
    "* Precise but slower\n",
    "* Scores candidates\n",
    "\n",
    "Models:\n",
    "\n",
    "* XGBoost\n",
    "* DNN\n",
    "* Transformer-based rankers\n",
    "\n",
    "üìå Interview gold:\n",
    "\n",
    "> ‚ÄúWe trade recall in stage one and precision in stage two.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ HANDLING COLD START\n",
    "\n",
    "### New Users\n",
    "\n",
    "* Popular items\n",
    "* Demographic-based\n",
    "\n",
    "### New Items\n",
    "\n",
    "* Content embeddings\n",
    "* Metadata-based similarity\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ EVALUATION METRICS\n",
    "\n",
    "### Offline Metrics\n",
    "\n",
    "* Precision@K\n",
    "* Recall@K\n",
    "* NDCG\n",
    "\n",
    "### Online Metrics\n",
    "\n",
    "* CTR\n",
    "* Watch time\n",
    "* Conversion\n",
    "\n",
    "üìå Strong line:\n",
    "\n",
    "> ‚ÄúOffline metrics don‚Äôt always correlate with business KPIs.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ REAL-TIME PERSONALIZATION\n",
    "\n",
    "* Context-aware recommendations\n",
    "* Session-based models\n",
    "* Streaming features\n",
    "\n",
    "Tech:\n",
    "\n",
    "* Kafka\n",
    "* Redis\n",
    "* Feature stores\n",
    "\n",
    "---\n",
    "\n",
    "## üîü GEN AI IN RECOMMENDATION (HOT üî•)\n",
    "\n",
    "### Use cases\n",
    "\n",
    "* Semantic search\n",
    "* Text-based recommendations\n",
    "* Cold-start mitigation\n",
    "\n",
    "### Example\n",
    "\n",
    "* Use LLM embeddings for item similarity\n",
    "* RAG-based recommendation explanations\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúLLMs enhance understanding; ML handles scale.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ EXPLAINABILITY\n",
    "\n",
    "* ‚ÄúWhy am I seeing this?‚Äù\n",
    "* Feature attribution\n",
    "* User trust\n",
    "\n",
    "Tools:\n",
    "\n",
    "* SHAP\n",
    "* Attention visualization\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£ FEEDBACK LOOP\n",
    "\n",
    "* Online learning\n",
    "* A/B testing\n",
    "* Retraining pipelines\n",
    "\n",
    "üìå Say:\n",
    "\n",
    "> ‚ÄúRecommendations are never static.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£3Ô∏è‚É£ FAILURE CASES\n",
    "\n",
    "* Filter bubbles\n",
    "* Popularity bias\n",
    "* Cold-start\n",
    "\n",
    "Mitigation:\n",
    "\n",
    "* Diversity constraints\n",
    "* Exploration‚Äìexploitation\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£4Ô∏è‚É£ INTERVIEWER SCORING CHECKLIST\n",
    "\n",
    "| Area              | Expected |\n",
    "| ----------------- | -------- |\n",
    "| Pipeline thinking | ‚úÖ        |\n",
    "| ML depth          | ‚úÖ        |\n",
    "| Business metrics  | ‚úÖ        |\n",
    "| Scalability       | ‚úÖ        |\n",
    "| GenAI awareness   | ‚úÖ        |\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa8ad3d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
