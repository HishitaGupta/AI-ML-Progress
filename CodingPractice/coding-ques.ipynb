{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d78447f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ PYTHON (Core Logic â€“ VERY COMMON)\n",
    "\n",
    "### **Q1. Reverse a string without using built-in reverse**\n",
    "\n",
    "```python\n",
    "s = \"machine\"\n",
    "rev = \"\"\n",
    "for ch in s:\n",
    "    rev = ch + rev\n",
    "print(rev)\n",
    "```\n",
    "\n",
    "âœ… **Checks**: loops, string immutability\n",
    "\n",
    "---\n",
    "\n",
    "### **Q2. Count frequency of words in a sentence**\n",
    "\n",
    "```python\n",
    "from collections import Counter\n",
    "\n",
    "s = \"ml is fun and ml is powerful\"\n",
    "freq = Counter(s.split())\n",
    "print(freq)\n",
    "```\n",
    "\n",
    "âœ… **Checks**: dictionaries, text processing\n",
    "\n",
    "---\n",
    "\n",
    "### **Q3. Find second largest element in a list**\n",
    "\n",
    "```python\n",
    "arr = [10, 5, 20, 8]\n",
    "unique = list(set(arr))\n",
    "unique.sort()\n",
    "print(unique[-2])\n",
    "```\n",
    "\n",
    "âœ… **Checks**: edge cases, duplicates\n",
    "\n",
    "---\n",
    "\n",
    "### **Q4. Lambda + filter**\n",
    "\n",
    "```python\n",
    "nums = [1,2,3,4,5,6]\n",
    "even = list(filter(lambda x: x % 2 == 0, nums))\n",
    "print(even)\n",
    "```\n",
    "\n",
    "âœ… **Checks**: functional programming\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ NUMPY (INTERVIEW FAVORITE)\n",
    "\n",
    "### **Q5. Create a 3Ã—3 identity matrix**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "np.eye(3)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Q6. Normalize a NumPy array**\n",
    "\n",
    "```python\n",
    "x = np.array([10, 20, 30])\n",
    "normalized = (x - x.mean()) / x.std()\n",
    "```\n",
    "\n",
    "âœ… **Used in ML preprocessing**\n",
    "\n",
    "---\n",
    "\n",
    "### **Q7. Find mean of each column**\n",
    "\n",
    "```python\n",
    "arr = np.array([[1,2,3],[4,5,6]])\n",
    "arr.mean(axis=0)\n",
    "```\n",
    "\n",
    "âœ… **axis understanding is CRUCIAL**\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ PANDAS (MOST ASKED FOR DATA SCIENCE)\n",
    "\n",
    "### **Q8. Read CSV and check missing values**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.isnull().sum()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Q9. Fill missing values with mean**\n",
    "\n",
    "```python\n",
    "df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Q10. GroupBy â€“ average salary per department**\n",
    "\n",
    "```python\n",
    "df.groupby('department')['salary'].mean()\n",
    "```\n",
    "\n",
    "âœ… **REAL interview question**\n",
    "\n",
    "---\n",
    "\n",
    "### **Q11. Create new column using lambda**\n",
    "\n",
    "```python\n",
    "df['age_plus_5'] = df['age'].apply(lambda x: x + 5)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ EXPLORATORY DATA ANALYSIS (EDA)\n",
    "\n",
    "### **Q12. Detect outliers using IQR**\n",
    "\n",
    "```python\n",
    "Q1 = df['salary'].quantile(0.25)\n",
    "Q3 = df['salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df[(df['salary'] < Q1 - 1.5*IQR) |\n",
    "              (df['salary'] > Q3 + 1.5*IQR)]\n",
    "```\n",
    "\n",
    "âœ… **Asked in real DS interviews**\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ MACHINE LEARNING (LOGIC-BASED CODING)\n",
    "\n",
    "### **Q13. Train-test split**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Q14. Build Linear Regression**\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Q15. Check overfitting**\n",
    "\n",
    "```python\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "```\n",
    "\n",
    "âž¡ï¸ Big gap = overfitting\n",
    "\n",
    "---\n",
    "\n",
    "### **Q16. Feature Scaling**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ CLUSTERING\n",
    "\n",
    "### **Q17. KMeans clustering**\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(X)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ DIMENSIONALITY REDUCTION\n",
    "\n",
    "### **Q18. PCA**\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "```\n",
    "\n",
    "âœ… **Why PCA?** remove correlation, reduce dimensions\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ DEEP LEARNING (ENTRY-LEVEL)\n",
    "\n",
    "### **Q19. Simple neural network (Keras)**\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ NLP / GEN AI (VERY TRENDING)\n",
    "\n",
    "### **Q20. Tokenization using HuggingFace**\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokens = tokenizer(\"AI is powerful\", return_tensors=\"pt\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Q21. Load LLM**\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Q22. What is temperature? (CODING)**\n",
    "\n",
    "```python\n",
    "model.generate(\n",
    "    inputs,\n",
    "    temperature=0.7,\n",
    "    max_length=50\n",
    ")\n",
    "```\n",
    "\n",
    "âž¡ï¸ **Low = deterministic**, **High = creative**\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ VERY COMMON LOGIC QUESTIONS (NO CODE)\n",
    "\n",
    "* Why scaling needed for KNN but not trees?\n",
    "* Why PCA before KMeans?\n",
    "* Why transformers over LSTMs?\n",
    "* Why cosine similarity in embeddings?\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0e009",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ðŸ”¥ PYTHON + LOGIC (TOP COMPANIES)\n",
    "\n",
    "## **Q1. Find first non-repeating character**\n",
    "\n",
    "ðŸ‘‰ Asked in Amazon, Adobe\n",
    "\n",
    "```python\n",
    "from collections import Counter\n",
    "\n",
    "s = \"aabbccdfe\"\n",
    "freq = Counter(s)\n",
    "\n",
    "for ch in s:\n",
    "    if freq[ch] == 1:\n",
    "        print(ch)\n",
    "        break\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Hashing + order preservation\n",
    "\n",
    "---\n",
    "\n",
    "## **Q2. Check if two strings are anagrams**\n",
    "\n",
    "```python\n",
    "from collections import Counter\n",
    "\n",
    "def is_anagram(s1, s2):\n",
    "    return Counter(s1) == Counter(s2)\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Text processing, NLP basics\n",
    "\n",
    "---\n",
    "\n",
    "## **Q3. Sliding window â€“ max sum subarray of size k**\n",
    "\n",
    "ðŸ‘‰ Google, Uber\n",
    "\n",
    "```python\n",
    "def max_sum(arr, k):\n",
    "    window_sum = sum(arr[:k])\n",
    "    max_sum = window_sum\n",
    "\n",
    "    for i in range(k, len(arr)):\n",
    "        window_sum += arr[i] - arr[i-k]\n",
    "        max_sum = max(max_sum, window_sum)\n",
    "\n",
    "    return max_sum\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Optimization thinking (O(n))\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ NUMPY (APPLIED)\n",
    "\n",
    "## **Q4. Row-wise normalization**\n",
    "\n",
    "```python\n",
    "norm = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "X_norm = X / norm\n",
    "```\n",
    "Euclidean normalisation , X = [[3, 4], [1, 2]] , norm = [[5.0], [âˆš5]] , linearalgebra module, axis =1 across row operation\n",
    "ðŸŽ¯ Vector math, embeddings\n",
    "\n",
    "---\n",
    "\n",
    "## **Q5. Cosine similarity**\n",
    "\n",
    "ðŸ‘‰ GenAI & NLP interviews\n",
    "\n",
    "```python\n",
    "def cosine_sim(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Embedding similarity\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ PANDAS (DATA SCIENTIST CORE)\n",
    "\n",
    "## **Q6. Top-N records per group**\n",
    "\n",
    "ðŸ‘‰ Asked in Flipkart, Walmart\n",
    "\n",
    "```python\n",
    "df.sort_values('salary', ascending=False)\\\n",
    "  .groupby('department')\\\n",
    "  .head(2)\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Groupby mastery\n",
    "\n",
    "---\n",
    "\n",
    "## **Q7. Rolling average (time series)**\n",
    "\n",
    "```python\n",
    "df['rolling_mean'] = df['sales'].rolling(window=7).mean()\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Real business data\n",
    "\n",
    "---\n",
    "\n",
    "## **Q8. Percentage contribution**\n",
    "\n",
    "```python\n",
    "df['pct'] = df['sales'] / df['sales'].sum() * 100\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Business analytics\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ STATISTICS (EXTREMELY IMPORTANT)\n",
    "\n",
    "## **Q9. Z-score outlier detection**\n",
    "\n",
    "```python\n",
    "z = (df['x'] - df['x'].mean()) / df['x'].std()\n",
    "outliers = df[abs(z) > 3]\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Stats + ML blend\n",
    "\n",
    "---\n",
    "\n",
    "## **Q10. Simulate Bernoulli trials**\n",
    "\n",
    "```python\n",
    "np.random.binomial(n=1, p=0.6, size=1000)\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Probability intuition\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ MACHINE LEARNING (CODING + THINKING)\n",
    "\n",
    "## **Q11. Custom train-test split**\n",
    "\n",
    "```python\n",
    "def split(X, y, test_size=0.2):\n",
    "    idx = int(len(X)*(1-test_size))\n",
    "    return X[:idx], X[idx:], y[:idx], y[idx:]\n",
    "```\n",
    "\n",
    "ðŸŽ¯ ML pipeline understanding\n",
    "\n",
    "---\n",
    "\n",
    "## **Q12. Why scaling before KNN? (Code demo)**\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Distance sensitivity\n",
    "\n",
    "---\n",
    "\n",
    "## **Q13. Feature importance (RandomForest)**\n",
    "\n",
    "```python\n",
    "model.feature_importances_\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Interpretability\n",
    "\n",
    "---\n",
    "\n",
    "## **Q14. Custom loss function**\n",
    "\n",
    "ðŸ‘‰ Research / advanced role\n",
    "\n",
    "```python\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Math + coding\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ CLUSTERING (REAL USE)\n",
    "\n",
    "## **Q15. Optimal K using Elbow**\n",
    "\n",
    "```python\n",
    "for k in range(1,10):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Model selection\n",
    "\n",
    "---\n",
    "\n",
    "## **Q16. Why DBSCAN over KMeans?**\n",
    "\n",
    "ðŸ‘‰ Interview expects:\n",
    "\n",
    "* Arbitrary shapes\n",
    "* Noise handling\n",
    "* No K needed\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ NLP / GEN AI (VERY HOT ðŸ”¥)\n",
    "\n",
    "## **Q17. TF-IDF from scratch**\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Text representation\n",
    "\n",
    "---\n",
    "\n",
    "## **Q18. Embedding similarity search**\n",
    "\n",
    "```python\n",
    "np.argmax([cosine_sim(q, e) for e in embeddings])\n",
    "```\n",
    "\n",
    "ðŸŽ¯ RAG systems\n",
    "\n",
    "---\n",
    "\n",
    "## **Q19. Explain attention with code**\n",
    "\n",
    "```python\n",
    "attention = softmax(Q @ K.T / sqrt(d_k)) @ V\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Transformer understanding\n",
    "\n",
    "---\n",
    "\n",
    "## **Q20. Temperature vs Top-p**\n",
    "\n",
    "ðŸ‘‰ Expected:\n",
    "\n",
    "* Temperature = randomness\n",
    "* Top-p = nucleus sampling\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ GEN AI SYSTEM QUESTIONS (CODING ROUND LEVEL)\n",
    "\n",
    "## **Q21. Simple RAG pipeline**\n",
    "\n",
    "```python\n",
    "query â†’ embedding â†’ vector DB â†’ LLM\n",
    "```\n",
    "\n",
    "ðŸŽ¯ Applied GenAI\n",
    "\n",
    "---\n",
    "\n",
    "## **Q22. Prevent hallucinations**\n",
    "\n",
    "Expected:\n",
    "\n",
    "* Retrieval grounding\n",
    "* Prompt constraints\n",
    "* Verification step\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸŸ¦ SQL-STYLE THINKING (VERY COMMON)\n",
    "\n",
    "## **Q23. Second highest salary**\n",
    "\n",
    "```python\n",
    "df['salary'].nlargest(2).iloc[-1]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Q24. Remove duplicates**\n",
    "\n",
    "```python\n",
    "df.drop_duplicates()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7c6d5e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
